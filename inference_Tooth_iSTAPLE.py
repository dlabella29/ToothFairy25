#!/usr/bin/env python
# inference_ToothFairy_ensemble.py           (Augâ€‘2025 â€“ iSTAPLE + cleanâ€‘up)

import os, sys, json, yaml, shutil, warnings, glob
import SimpleITK as sitk, torch
import numpy as np

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ PATHS (edit if your tree changes) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
BASE     = "/home/dlabella29/Auto3DSegDL/PythonProject/DEEP-PSMA_BaseLine/ToothFairy"
INPUT    = os.path.join(BASE, "input",  "images", "cbct")
BUNDLES  = os.path.join(BASE, "AutoToothWorkDirChallenge")            # segresnet_0 â€¦ 5
TMP      = os.path.join(BASE, "tmp")
CONV     = os.path.join(TMP,  "converted")
OUTIMG   = os.path.join(BASE, "output", "images", "oral-pharyngeal-segmentation")
num_folds = 5

shutil.rmtree(TMP, ignore_errors=True)  # clean tmp/ completely

for d in (TMP, CONV, OUTIMG): os.makedirs(d, exist_ok=True)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ HOUSEâ€‘KEEPING â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
warnings.filterwarnings("ignore", category=UserWarning,
                        message="A NumPy version .* is required for this")
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"ðŸ’»  inference device: {device}\n")

# Clean old prediction_testing folders so that only fresh masks exist
for pred_dir in glob.glob(os.path.join(BUNDLES, "segresnet_*", "prediction_testing")):
    if os.path.isdir(pred_dir):
        print(f"ðŸ§¹ removing stale predictions in {pred_dir}")
        shutil.rmtree(pred_dir)           # delete dir and its contents
        os.makedirs(pred_dir, exist_ok=True)



sys.path.insert(0, os.path.abspath(os.path.dirname(__file__)))
from segmenter import run_segmenter                           # MONAI bundle API

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1. CONVERT FIRST .mha â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
mha_files = sorted(f for f in os.listdir(INPUT) if f.lower().endswith(".mha"))
if not mha_files:
    raise FileNotFoundError(f"No .mha files found in {INPUT}")
mha_fp = os.path.join(INPUT, mha_files[0])
nii_fp = os.path.join(CONV,  mha_files[0].replace(".mha", ".nii.gz"))
print(f"âžŠ  reading   : {mha_fp}")
sitk.WriteImage(sitk.ReadImage(mha_fp), nii_fp, useCompression=True)
print(f"    written  : {nii_fp}\n")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 2. BUILD TEST LIST JSON â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
json_fp = os.path.join(TMP, "ToothFairy_test_data.json")
json.dump({"testing": [{"image": [os.path.basename(nii_fp)]}]},
          open(json_fp, "w"), indent=2)
print(f"âž‹  JSON      : {json_fp}\n")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 3. FOLD CONFIG PATHS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
CFG = [os.path.join(BUNDLES, f"segresnet_{i}", "configs", "hyper_parameters.yaml")
       for i in range(6)]

def infer_fold(i: int) -> str:
    """Run bundle *i*, copy its mask into tmp/, return that path."""
    cfg = CFG[i]
    assert os.path.isfile(cfg), f"Config missing: {cfg}"
    bundle_root = os.path.dirname(os.path.dirname(cfg))

    override = {
        "bundle_root":         bundle_root,
        "data_file_base_dir":  CONV,
        "data_list_file_path": json_fp,
        "infer#enabled":       True,
    }

    print(f"â–¶ fold {i}: {bundle_root}")
    run_segmenter(config_file=cfg, **override)

    legacy_dir = os.path.join(bundle_root, "prediction_testing")
    tmp_dir    = os.path.join(TMP, f"fold_{i}", "prediction_testing")
    os.makedirs(tmp_dir, exist_ok=True)

    preds = [f for f in os.listdir(legacy_dir) if f.endswith(".nii.gz")]
    if not preds:
        raise RuntimeError(f"Fold {i}: no .nii.gz in {legacy_dir}")
    src = os.path.join(legacy_dir, preds[0])
    dst = os.path.join(tmp_dir,    preds[0])
    shutil.copy2(src, dst)
    return dst

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 4. RUN ALL FOLDS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
pred_paths = [infer_fold(i) for i in range(num_folds)]
seg_images = [sitk.ReadImage(p) for p in pred_paths]

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 5. LABEL FUSION WITH MultiLabelâ€‘STAPLE â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
staple = sitk.MultiLabelSTAPLEImageFilter()
staple.SetMaximumNumberOfIterations(3)
staple.SetTerminationUpdateThreshold(1e-4)

print("\nðŸ§®  running MultiLabelâ€‘STAPLE â€¦")
fused = staple.Execute(seg_images)
fused = sitk.Cast(fused, sitk.sitkUInt8)          # 0â€“46 classes â†’ uint8
fused.CopyInformation(seg_images[0])

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 5b. RELABEL BEFORE SAVING  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# mapping: old â†’ new
REMAP = {19: 53, 20: 52, 29: 51, 30: 50, 39: 48, 40: 47}

arr = sitk.GetArrayFromImage(fused)               # zâ€‘yâ€‘x numpy array
for old, new in REMAP.items():
    arr[arr == old] = new

# optionally verify that all old labels are gone
# assert not np.isin(list(REMAP.keys()), arr)

fused = sitk.GetImageFromArray(arr)
fused.CopyInformation(seg_images[0])              # preserve origin/spacing

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 6. WRITE OUTPUT  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
out_fp = os.path.join(OUTIMG, "ensembled_segmentation.mha")
if os.path.exists(out_fp):                        # avoid FileNotFoundError
    os.remove(out_fp)

sitk.WriteImage(fused, out_fp, useCompression=True)

print(f"\nâœ…  relabelled + iSTAPLE fusion mask â†’ {out_fp}\n"
      f"   perâ€‘fold fresh outputs are under {TMP}/fold_*/prediction_testing/")

